name: Run Azure ML Dataprep and Training Pipelines

on:
  workflow_dispatch:
  push:
    branches:
      - main
    paths:
      - 'pipelines/**.yaml'
      - '.github/workflows/run-azure-preprocess-n-train-pipeline.yml'

env:
  GROUP: mlops-project
  WORKSPACE: mlops-project-ai
  LOCATION: westeurope

jobs:
  build-and-upload-package:
    permissions:
      contents: write
      packages: write 
    name: Build and Upload MLOps Package
    runs-on: [self-hosted, Linux]

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'

    - name: Install build tools
      run: pip install setuptools wheel twine

    - name: Build package
      run: |
        cd components/dataprep/code
        python setup.py sdist bdist_wheel

    - name: Check if version exists on PyPI
      id: check_version
      run: |
        cd components/dataprep/code
        VERSION=$(python setup.py --version)
        echo "Detected version: $VERSION"
        echo "version=$VERSION" >> $GITHUB_OUTPUT
        EXISTS=$(curl -s https://pypi.org/pypi/mlops-cleaning/json | \
          python -c "import sys, json; data=json.load(sys.stdin); print('true' if '$VERSION' in data['releases'] else 'false')")
        if [ \"$EXISTS\" == \"true\" ]; then
          echo \"Version $VERSION already exists on PyPI. Skipping upload.\"
          echo \"skip_upload=true\" >> $GITHUB_OUTPUT
        else
          echo \"skip_upload=false\" >> $GITHUB_OUTPUT
        fi



    - name: Publish to PyPI
      if: steps.check_version.outputs.skip_upload == 'false'
      run: |
        cd components/dataprep/code
        pip install twine
        python -m twine upload \
          --repository-url https://upload.pypi.org/legacy/ \
          --username __token__ \
          --password ${{ secrets.PYPI_TOKEN }} \
          dist/*
          
  run-pipelines:
    needs: build-and-upload-package
    runs-on: [self-hosted, Linux]

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Login to Azure
      uses: azure/login@v2
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}

    - name: Install Azure ML CLI extension
      run: |
        python3 -m venv .venv
        source .venv/bin/activate
        pip install --upgrade pip
        pip install rpds-py
        az extension remove --name ml || true
        az extension add --name ml --allow-preview
        az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION

    - name: Create Azure ML Compute
      run: |
        az ml compute create --file ./environment/compute.yaml

    - name: Start Azure ML Compute
      run: |
        az ml compute start --name ai-training-compute
      continue-on-error: true

    - name: Create Environments
      run: |
        az ml environment create --file ./environment/pillow.yaml || true
        az ml environment create --file ./environment/tensorflow.yaml || true

    - name: Create Components
      run: |
        az ml component create --file ./components/dataprep/dataprep.yaml --set version=0.2.${{ github.run_number }}
        az ml component create --file ./components/dataprep/split.yaml --set version=0.2.${{ github.run_number }}
        az ml component create --file ./components/training/training.yaml --set version=0.2.${{ github.run_number }}

    - name: Upload H5 files as Data Assets
      run: |
        az ml data create --name train_data \
                          --type uri_file \
                          --path ./data/train_data.h5 \
                          --version 0.2.${{ github.run_number }} \
                          --description "Training input data"
                          
        az ml data create --name train_label \
                          --type uri_file \
                          --path ./data/train_label.h5 \
                          --version 0.2.${{ github.run_number }} \
                          --description "Training labels"

    - name: Run Preprocessing Pipeline
      run: |
        az ml job create \
          --file ./pipelines/preprocessing.yaml \
          --stream \
          --set name=preprocessing-${{ github.sha }}-${{ github.run_id }} \
              inputs.job_id=preprocessing-${{ github.sha }}-${{ github.run_id }}

        echo "preprocessing-${{ github.sha }}-${{ github.run_id }}"
          
    - name: Register Preprocessed Dataset
      run: |
        az ml data create \
          --name data_split \
          --type uri_folder \
          --path "azureml://subscriptions/${{ secrets.AZURE_SUBSCRIPTION_ID }}/resourcegroups/$GROUP/workspaces/$WORKSPACE/datastores/workspaceblobstore/paths/azureml/preprocessing-${{ github.sha }}-${{ github.run_id }}/output_data/" \
          --description "Training split from preprocessing pipeline"
          
        echo "preprocessing-${{ github.sha }}-${{ github.run_id }}"
        

    - name: Run Training Pipeline & Stop Compute
      run: |
        az ml job create \
          --file ./pipelines/training.yaml \
          --stream \
          --set name=training-${{ github.sha }}-${{ github.run_id }}
        az ml compute stop --name ai-training-compute
      continue-on-error: true
