name: Run Azure ML Dataprep and Training Pipelines

on:
  workflow_dispatch:
  push:
    branches:
      - main
    paths:
      - 'pipelines/**.yaml'
      - '.github/workflows/run-azure-preprocess-n-train-pipeline.yml'

env:
  GROUP: mlops-project
  WORKSPACE: mlops-project-ai
  LOCATION: westeurope

jobs:
  run-pipelines:
    runs-on: [self-hosted, Linux]

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Login to Azure
      uses: azure/login@v2
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}

    - name: Install Azure ML CLI extension
      run: |
        python3 -m venv .venv
        source .venv/bin/activate
        pip install --upgrade pip
        pip install rpds-py
        az extension remove --name ml || true
        az extension add --name ml --allow-preview
        az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
        
    - name: Create Azure ML Compute
      run: |
        az ml compute create --file ./environment/compute.yaml
        
    - name: Start Azure ML Compute
      run: |
        az ml compute start --name ai-training-compute
      continue-on-error: true

    - name: Create Environments
      run: |
        az ml environment create --file ./environment/pillow.yaml || true
        az ml environment create --file ./environment/tensorflow.yaml || true
        
    - name: Create Components
      run: |
        az ml component create --file ./components/dataprep/dataprep.yaml --set version=0.2.${{ github.run_number }}
        az ml component create --file ./components/dataprep/split.yaml --set version=0.2.${{ github.run_number }}
        az ml component create --file ./components/training/training.yaml --set version=0.2.${{ github.run_number }}
        
    - name: Submit Preprocessing Pipeline and Capture Job Name
      id: submit_pipeline
      run: |
        JOB_NAME=preprocessing-${{ github.sha }}-${{ github.run_id }}
        echo "Submitting pipeline job: $JOB_NAME"
        
        az ml job create \
          --file ./pipelines/preprocessing.yaml \
          --set name=$JOB_NAME > job_output.json
    
        echo "job_name=$JOB_NAME" >> $GITHUB_OUTPUT
    
    - name: Get splitted_data Output Path
      id: get_output_path
      run: |
        JOB_NAME=${{ steps.submit_pipeline.outputs.job_name }}
        echo "⏳ Waiting for job to complete: $JOB_NAME"
        az ml job wait --name $JOB_NAME
        OUTPUT_PATH=$(az ml job show --name ${{ steps.submit_pipeline.outputs.job_name }} \
          --query "outputs.splitted_data.path" -o tsv)
        
        echo "Output path: $OUTPUT_PATH"
        echo "splitted_data_path=$OUTPUT_PATH" >> $GITHUB_OUTPUT
    
    - name: Register splitted_data as Data Asset
      run: |
        az ml data create \
          --name splitted_train_data \
          --type uri_folder \
          --description "Split dataset from preprocessing pipeline" \
          --path "${{ steps.get_output_path.outputs.splitted_data_path }}"

          
    
    - name: Run Training Pipeline & Stop Compute
      run: |
        az ml job create \
          --file ./pipelines/training.yaml \
          --stream \
          --set name=training-${{ github.sha }}-${{ github.run_id }}
          
        az ml compute stop --name ai-training-compute
      continue-on-error: true
